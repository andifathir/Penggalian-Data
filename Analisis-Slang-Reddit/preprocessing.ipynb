{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title  Text  Upvotes  \\\n",
      "0  Are you ok with the DOD removing articles from...  None     7614   \n",
      "1  Are you ok with the DOD removing articles from...  None     7614   \n",
      "2  Are you ok with the DOD removing articles from...  None     7614   \n",
      "3  Are you ok with the DOD removing articles from...  None     7614   \n",
      "4  Are you ok with the DOD removing articles from...  None     7614   \n",
      "\n",
      "                                        Comment Text  Comment Upvotes  \\\n",
      "0            Navajo code talkers are still not back.             2571   \n",
      "1  Iâ€™m just thinking about how these are the same...             5572   \n",
      "2  Anyone who is okay with this does not respect ...             1696   \n",
      "3  Itâ€™s not DEI, but racism when you remove MOH p...              579   \n",
      "4  You should just call it what it is. The curren...              796   \n",
      "\n",
      "   Comment Timestamp  Subreddit  Original Timestamp  \n",
      "0       1.742301e+09  AskReddit        1.742300e+09  \n",
      "1       1.742300e+09  AskReddit        1.742300e+09  \n",
      "2       1.742301e+09  AskReddit        1.742300e+09  \n",
      "3       1.742302e+09  AskReddit        1.742300e+09  \n",
      "4       1.742300e+09  AskReddit        1.742300e+09  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast  # To safely evaluate the string as a Python list\n",
    "\n",
    "# Load your dataset (Assume it's a CSV file, adjust path as needed)\n",
    "df = pd.read_csv('reddit_data_with_comments.csv')\n",
    "\n",
    "# A function to split the comment data\n",
    "def separate_comments(row):\n",
    "    # Parse the 'Comments Data' which is in string format\n",
    "    try:\n",
    "        comments_data = ast.literal_eval(row['Comments Data'])  # Safely convert string to list\n",
    "        comment_rows = []\n",
    "        \n",
    "        # Iterate through each comment in the list\n",
    "        for comment in comments_data:\n",
    "            comment_text = comment[0]  # First element is the comment text\n",
    "            comment_upvotes = comment[1]  # Second element is the upvotes\n",
    "            comment_timestamp = comment[2]  # Third element is the timestamp\n",
    "            \n",
    "            # Create a new row for each comment\n",
    "            comment_row = {\n",
    "                'Title': row['Title'],\n",
    "                'Text': row['Text'] if pd.notnull(row['Text']) else None,\n",
    "                'Upvotes': row['Upvotes'],\n",
    "                'Comment Text': comment_text,\n",
    "                'Comment Upvotes': comment_upvotes,\n",
    "                'Comment Timestamp': comment_timestamp,\n",
    "                'Subreddit': row['Subreddit'],\n",
    "                'Original Timestamp': row['Timestamp']\n",
    "            }\n",
    "            comment_rows.append(comment_row)\n",
    "        return comment_rows\n",
    "    except (ValueError, SyntaxError):\n",
    "        # Handle cases where Comments Data is malformed\n",
    "        return []\n",
    "\n",
    "# Create a list to store all individual comments\n",
    "all_comments = []\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for _, row in df.iterrows():\n",
    "    all_comments.extend(separate_comments(row))\n",
    "\n",
    "# Convert the list of comments into a new DataFrame\n",
    "new_df = pd.DataFrame(all_comments)\n",
    "\n",
    "# Save the new DataFrame to a CSV (or you can process it further)\n",
    "new_df.to_csv('separated_comments.csv', index=False)\n",
    "\n",
    "# Show the first few rows of the new DataFrame\n",
    "print(new_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text  Upvotes  \\\n",
      "0  Title: Are you ok with the DOD removing articl...     7614   \n",
      "1  Title: Are you ok with the DOD removing articl...     7614   \n",
      "2  Title: Are you ok with the DOD removing articl...     7614   \n",
      "3  Title: Are you ok with the DOD removing articl...     7614   \n",
      "4  Title: Are you ok with the DOD removing articl...     7614   \n",
      "\n",
      "   Comment Upvotes  Comment Timestamp  Subreddit  Original Timestamp  \n",
      "0             2571       1.742301e+09  AskReddit        1.742300e+09  \n",
      "1             5572       1.742300e+09  AskReddit        1.742300e+09  \n",
      "2             1696       1.742301e+09  AskReddit        1.742300e+09  \n",
      "3              579       1.742302e+09  AskReddit        1.742300e+09  \n",
      "4              796       1.742300e+09  AskReddit        1.742300e+09  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast  # To safely evaluate the string as a Python list\n",
    "\n",
    "# Load your dataset (Assume it's a CSV file, adjust path as needed)\n",
    "df = pd.read_csv('reddit_data_with_comments.csv')\n",
    "\n",
    "# A function to split the comment data\n",
    "def separate_comments(row):\n",
    "    # Parse the 'Comments Data' which is in string format\n",
    "    try:\n",
    "        comments_data = ast.literal_eval(row['Comments Data'])  # Safely convert string to list\n",
    "        comment_rows = []\n",
    "        \n",
    "        # Iterate through each comment in the list\n",
    "        for comment in comments_data:\n",
    "            comment_text = comment[0]  # First element is the comment text\n",
    "            comment_upvotes = comment[1]  # Second element is the upvotes\n",
    "            comment_timestamp = comment[2]  # Third element is the timestamp\n",
    "            \n",
    "            # Combine the Title, Text, and Comment Text into one column 'Text'\n",
    "            combined_text = f\"Title: {row['Title']}\\nText: {row['Text'] if pd.notnull(row['Text']) else ''}\\nComment: {comment_text}\"\n",
    "            \n",
    "            # Create a new row for each comment\n",
    "            comment_row = {\n",
    "                'Text': combined_text,\n",
    "                'Upvotes': row['Upvotes'],\n",
    "                'Comment Upvotes': comment_upvotes,\n",
    "                'Comment Timestamp': comment_timestamp,\n",
    "                'Subreddit': row['Subreddit'],\n",
    "                'Original Timestamp': row['Timestamp']\n",
    "            }\n",
    "            comment_rows.append(comment_row)\n",
    "        return comment_rows\n",
    "    except (ValueError, SyntaxError):\n",
    "        # Handle cases where Comments Data is malformed\n",
    "        return []\n",
    "\n",
    "# Create a list to store all individual comments\n",
    "all_comments = []\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for _, row in df.iterrows():\n",
    "    all_comments.extend(separate_comments(row))\n",
    "\n",
    "# Convert the list of comments into a new DataFrame\n",
    "new_df = pd.DataFrame(all_comments)\n",
    "\n",
    "# Save the new DataFrame to a CSV (or you can process it further)\n",
    "new_df.to_csv('separated_comments_combined.csv', index=False)\n",
    "\n",
    "# Show the first few rows of the new DataFrame\n",
    "print(new_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    Text  Upvotes  \\\n",
      "60136  Title: Atletico Madrid 2 - [3] Barcelona - Lam...     5384   \n",
      "32015  Title: JUST EAT THE CRUST IT'S JUST BREAD\\nTex...     1753   \n",
      "28769  Title: will be less talkative from now on.\\nTe...     1330   \n",
      "46419  Title: What is up with Casey Anthony popping u...      672   \n",
      "7464   Title: Redditors, how do you feel a grassroots...     9585   \n",
      "15303  Title: what was the first wine you tried that ...       17   \n",
      "78323  Title: What are the best online PvP games to g...      328   \n",
      "53134  Title: [DR] Christian Eriksen hasn't received ...      532   \n",
      "78534  Title: Do current-gen consoles feel outdated e...        0   \n",
      "63652  Title: Dujon Sterling calling Celtic Park a Sh...      182   \n",
      "27494  Title: This man had kids for one reason.\\nText...    79825   \n",
      "74931  Title: On March 15th, 2069 years ago, Assassin...     7974   \n",
      "40681  Title: pee pee shaped cheeto\\nText: \\nComment:...        1   \n",
      "6792   Title: You are forced to buy one thing everyda...       78   \n",
      "43457  Title: What's the deal with Schumer and AOC fi...     4081   \n",
      "74522  Title: The Day Before studio reportedly sues R...     5050   \n",
      "73351  Title: 'The future of hardware at Valve is bri...     7424   \n",
      "81433  Title: Split Fiction Hits 2 Million Sales Afte...     4879   \n",
      "77293  Title: This â€˜Street Fighterâ€™ comic predates th...      143   \n",
      "51154  Title: What is up with Trump saying he stopped...     1385   \n",
      "28944  Title: will be less talkative from now on.\\nTe...     1330   \n",
      "35001  Title: Why tf did they get d0wnv0ted? ðŸ˜­\\nText:...      621   \n",
      "62315  Title: Newcastle United wins first-ever League...     3097   \n",
      "8131   Title: What is your f*** everything song?\\nTex...      947   \n",
      "40054  Title: Make the comments section look like a t...      532   \n",
      "67534  Title: What was the first game that made you r...       93   \n",
      "30326  Title: This meme is exclusive to USA\\nText: \\n...     1764   \n",
      "90120  Title: Are only white people attacked by bears...     1960   \n",
      "27917  Title: My brother has a funny wifi name.\\nText...     2658   \n",
      "59146  Title: Interaction between Timber & Maresca\\nT...     1066   \n",
      "\n",
      "       Comment Upvotes  Comment Timestamp          Subreddit  \\\n",
      "60136                6       1.742179e+09             soccer   \n",
      "32015                1       1.742271e+09              memes   \n",
      "28769                1       1.742179e+09              funny   \n",
      "46419               36       1.741587e+09       OutOfTheLoop   \n",
      "7464                -3       1.742232e+09          AskReddit   \n",
      "15303                1       1.742302e+09          AskReddit   \n",
      "78323                2       1.742073e+09             gaming   \n",
      "53134               -7       1.742319e+09             soccer   \n",
      "78534                1       1.742228e+09             gaming   \n",
      "63652                1       1.742236e+09             soccer   \n",
      "27494               32       1.742076e+09              funny   \n",
      "74931                1       1.742102e+09             gaming   \n",
      "40681                1       1.742327e+09          teenagers   \n",
      "6792                 1       1.742326e+09          AskReddit   \n",
      "43457               16       1.741975e+09       OutOfTheLoop   \n",
      "74522                1       1.742156e+09             gaming   \n",
      "73351               36       1.742132e+09             gaming   \n",
      "81433              -24       1.741978e+09             gaming   \n",
      "77293                3       1.742130e+09             gaming   \n",
      "51154                0       1.740801e+09       OutOfTheLoop   \n",
      "28944               15       1.742080e+09              funny   \n",
      "35001              -38       1.742316e+09          teenagers   \n",
      "62315               43       1.742169e+09             soccer   \n",
      "8131               237       1.742261e+09          AskReddit   \n",
      "40054                2       1.742260e+09          teenagers   \n",
      "67534                1       1.742328e+09             gaming   \n",
      "30326                1       1.742315e+09              memes   \n",
      "90120                2       1.742314e+09  NoStupidQuestions   \n",
      "27917                1       1.742238e+09              funny   \n",
      "59146                2       1.742263e+09             soccer   \n",
      "\n",
      "       Original Timestamp  \n",
      "60136        1.742162e+09  \n",
      "32015        1.742260e+09  \n",
      "28769        1.742054e+09  \n",
      "46419        1.741569e+09  \n",
      "7464         1.742221e+09  \n",
      "15303        1.742299e+09  \n",
      "78323        1.742060e+09  \n",
      "53134        1.742308e+09  \n",
      "78534        1.742225e+09  \n",
      "63652        1.742198e+09  \n",
      "27494        1.742055e+09  \n",
      "74931        1.742081e+09  \n",
      "40681        1.742326e+09  \n",
      "6792         1.742312e+09  \n",
      "43457        1.741969e+09  \n",
      "74522        1.742091e+09  \n",
      "73351        1.742118e+09  \n",
      "81433        1.741972e+09  \n",
      "77293        1.742085e+09  \n",
      "51154        1.740788e+09  \n",
      "28944        1.742054e+09  \n",
      "35001        1.742314e+09  \n",
      "62315        1.742150e+09  \n",
      "8131         1.742258e+09  \n",
      "40054        1.742229e+09  \n",
      "67534        1.742324e+09  \n",
      "30326        1.742297e+09  \n",
      "90120        1.742223e+09  \n",
      "27917        1.742084e+09  \n",
      "59146        1.742200e+09  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('separated_comments_combined.csv')\n",
    "\n",
    "# Randomly select 30 rows from the dataset without fixing the random state\n",
    "sample_df = df.sample(n=30)\n",
    "\n",
    "# Display the selected columns for classification\n",
    "sample_df = sample_df[['Text', 'Upvotes', 'Comment Upvotes', 'Comment Timestamp', 'Subreddit', 'Original Timestamp']]\n",
    "\n",
    "# Display the selected rows\n",
    "print(sample_df)\n",
    "\n",
    "# Optionally, save the selected rows to a CSV file for easy access\n",
    "sample_df.to_csv('sample_for_classification.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Text  Upvotes  \\\n",
      "0   Title: Atletico Madrid 2 - [3] Barcelona - Lam...     5384   \n",
      "1   Title: JUST EAT THE CRUST IT'S JUST BREAD\\nTex...     1753   \n",
      "2   Title: will be less talkative from now on.\\nTe...     1330   \n",
      "3   Title: What is up with Casey Anthony popping u...      672   \n",
      "4   Title: Redditors, how do you feel a grassroots...     9585   \n",
      "5   Title: what was the first wine you tried that ...       17   \n",
      "6   Title: What are the best online PvP games to g...      328   \n",
      "7   Title: [DR] Christian Eriksen hasn't received ...      532   \n",
      "8   Title: Do current-gen consoles feel outdated e...        0   \n",
      "9   Title: Dujon Sterling calling Celtic Park a Sh...      182   \n",
      "10  Title: This man had kids for one reason.\\nText...    79825   \n",
      "11  Title: On March 15th, 2069 years ago, Assassin...     7974   \n",
      "12  Title: pee pee shaped cheeto\\nText: \\nComment:...        1   \n",
      "13  Title: You are forced to buy one thing everyda...       78   \n",
      "14  Title: What's the deal with Schumer and AOC fi...     4081   \n",
      "15  Title: The Day Before studio reportedly sues R...     5050   \n",
      "16  Title: 'The future of hardware at Valve is bri...     7424   \n",
      "17  Title: Split Fiction Hits 2 Million Sales Afte...     4879   \n",
      "18  Title: This â€˜Street Fighterâ€™ comic predates th...      143   \n",
      "19  Title: What is up with Trump saying he stopped...     1385   \n",
      "20  Title: will be less talkative from now on.\\nTe...     1330   \n",
      "21  Title: Why tf did they get d0wnv0ted? ðŸ˜­\\nText:...      621   \n",
      "22  Title: Newcastle United wins first-ever League...     3097   \n",
      "23  Title: What is your f*** everything song?\\nTex...      947   \n",
      "24  Title: Make the comments section look like a t...      532   \n",
      "25  Title: What was the first game that made you r...       93   \n",
      "26  Title: This meme is exclusive to USA\\nText: \\n...     1764   \n",
      "27  Title: Are only white people attacked by bears...     1960   \n",
      "28  Title: My brother has a funny wifi name.\\nText...     2658   \n",
      "29  Title: Interaction between Timber & Maresca\\nT...     1066   \n",
      "\n",
      "    Comment Upvotes Comment Date          Subreddit        Date  \n",
      "0                 6   2025-03-17             soccer  2025-03-16  \n",
      "1                 1   2025-03-18              memes  2025-03-18  \n",
      "2                 1   2025-03-17              funny  2025-03-15  \n",
      "3                36   2025-03-10       OutOfTheLoop  2025-03-10  \n",
      "4                -3   2025-03-17          AskReddit  2025-03-17  \n",
      "5                 1   2025-03-18          AskReddit  2025-03-18  \n",
      "6                 2   2025-03-15             gaming  2025-03-15  \n",
      "7                -7   2025-03-18             soccer  2025-03-18  \n",
      "8                 1   2025-03-17             gaming  2025-03-17  \n",
      "9                 1   2025-03-17             soccer  2025-03-17  \n",
      "10               32   2025-03-15              funny  2025-03-15  \n",
      "11                1   2025-03-16             gaming  2025-03-15  \n",
      "12                1   2025-03-18          teenagers  2025-03-18  \n",
      "13                1   2025-03-18          AskReddit  2025-03-18  \n",
      "14               16   2025-03-14       OutOfTheLoop  2025-03-14  \n",
      "15                1   2025-03-16             gaming  2025-03-16  \n",
      "16               36   2025-03-16             gaming  2025-03-16  \n",
      "17              -24   2025-03-14             gaming  2025-03-14  \n",
      "18                3   2025-03-16             gaming  2025-03-16  \n",
      "19                0   2025-03-01       OutOfTheLoop  2025-03-01  \n",
      "20               15   2025-03-15              funny  2025-03-15  \n",
      "21              -38   2025-03-18          teenagers  2025-03-18  \n",
      "22               43   2025-03-16             soccer  2025-03-16  \n",
      "23              237   2025-03-18          AskReddit  2025-03-18  \n",
      "24                2   2025-03-18          teenagers  2025-03-17  \n",
      "25                1   2025-03-18             gaming  2025-03-18  \n",
      "26                1   2025-03-18              memes  2025-03-18  \n",
      "27                2   2025-03-18  NoStupidQuestions  2025-03-17  \n",
      "28                1   2025-03-17              funny  2025-03-16  \n",
      "29                2   2025-03-18             soccer  2025-03-17  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('sample_for_classification.csv')\n",
    "\n",
    "# Convert 'Original Timestamp' and 'Comment Timestamp' to datetime\n",
    "df[\"Timestamp\"] = pd.to_datetime(df[\"Original Timestamp\"], unit=\"s\")  # Post date\n",
    "df[\"Comment Timestamp\"] = pd.to_datetime(df[\"Comment Timestamp\"], unit=\"s\")  # Comment date\n",
    "\n",
    "# Extract only the date for both post and comment timestamps\n",
    "df[\"Date\"] = df[\"Timestamp\"].dt.date  # Post date\n",
    "df[\"Comment Date\"] = df[\"Comment Timestamp\"].dt.date  # Comment date\n",
    "\n",
    "# Display the selected columns for classification\n",
    "df = df[['Text', 'Upvotes', 'Comment Upvotes', 'Comment Date', 'Subreddit', 'Date']]\n",
    "\n",
    "# Display the selected rows\n",
    "print(df)\n",
    "\n",
    "# Optionally, save the selected rows to a CSV file for easy access\n",
    "df.to_csv('sample_for_classification_FixedDate.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
